# -*- coding: utf-8 -*-
"""Credit Card

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ivdhAGUc4Fyx2T4qtWTJ2bJWV6Q_fIoi
"""

import pandas as pd

data = pd.read_csv(r'C:\Users\HP\OneDrive\Nick final year document\Main Detect\ml-streamlit_app\df\creditCards.csv')

data.head()

pd.options.display.max_columns = None

data.head()

data.shape

print("Number of columns: {}".format(data.shape[1]))
print("Number of rows: {}".format(data.shape[0]))

data.info()

data.isnull().sum()

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
data['Amount'] = sc.fit_transform(pd.DataFrame(data['Amount']))

data.head()

data = data.drop(['Time'], axis=1)

data.head()

data.duplicated().sum()

data = data.drop_duplicates()

data.shape

data['Class'].value_counts()

import seaborn as sns
import matplotlib.pyplot as plt

# Pie chart visualization for class distribution
class_counts = data['Class'].value_counts()
plt.figure(figsize=(6,6))
class_counts.plot.pie(autopct='%1.1f%%', colors=['#ff9999','#66b3ff'], labels=["Legit", "Fraud"])
plt.title('Class Distribution (Legit vs. Fraud)')
plt.ylabel('')
plt.show()

# Stacked bar chart for visualizing feature distributions across classes
plt.figure(figsize=(10,6))
sns.histplot(data=data, x='Amount', hue='Class', multiple='stack', kde=True)
plt.title('Amount Distribution by Class (Legit vs. Fraud)')
plt.show()


X = data.drop('Class', axis=1)
y =data['Class']

from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report

data.dropna(inplace=True)



X = data.drop('Class', axis=1)
y = data['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

classifiers = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "Decision Tree Classifier": DecisionTreeClassifier()
}

for name, clf in classifiers.items():
    print(f"\n============={name}==============")
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(f"\n Accuracy Score: {accuracy_score(y_test, y_pred)}")
    print(f"\n Precision Score: {precision_score(y_test, y_pred)}")
    print(f"\n Recall Score: {recall_score(y_test, y_pred)}")
    print(f"\n F1 Score: {f1_score(y_test, y_pred)}")

# Undersampling

normal = data[data['Class']==0]
fraud = data[data['Class']==1]

normal.shape

fraud.shape

# Calculate how many legit samples you need
normal_sample_size = int(fraud.shape[0] * 10)  # 10% of fraud samples (or any fraction you prefer)

# Take that many samples from legit class
normal_sample = normal.sample(n=normal_sample_size, random_state=42)

# Combine the undersampled legit class with the fraud class
new_data = pd.concat([normal_sample, fraud], ignore_index=True)

# Check the new class distribution
new_data['Class'].value_counts()


new_data = pd.concat([normal_sample,fraud], ignore_index = True)

new_data.head()

new_data['Class'].value_counts()

X = new_data.drop('Class', axis = 1)
y = new_data['Class']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

classifiers = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "Decision Tree Classifier": DecisionTreeClassifier()
}

for name, clf in classifiers.items():
    print(f"\n============={name}==============")
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(f"\n Accuracy Score: {accuracy_score(y_test, y_pred)}")
    print(f"\n Precision Score: {precision_score(y_test, y_pred)}")
    print(f"\n Recall Score: {recall_score(y_test, y_pred)}")
    print(f"\n F1 Score: {f1_score(y_test, y_pred)}")
    
    # Collect metrics for plotting
undersample_metrics = {
    "Model": [],
    "Accuracy": [],
    "Precision": [],
    "Recall": [],
    "F1 Score": []
}

for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    undersample_metrics["Model"].append(name)
    undersample_metrics["Accuracy"].append(accuracy_score(y_test, y_pred))
    undersample_metrics["Precision"].append(precision_score(y_test, y_pred))
    undersample_metrics["Recall"].append(recall_score(y_test, y_pred))
    undersample_metrics["F1 Score"].append(f1_score(y_test, y_pred))

# OVERSAMPLING

X = data.drop('Class', axis=1)
y = data['Class']

X.shape

y.shape

import imblearn
print(imblearn.__version__)
from imblearn.over_sampling import SMOTE

X_res, y_res = SMOTE().fit_resample(X,y)

y_res.value_counts()

X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)
classifiers = {
    "Logistic Regression": LogisticRegression(),
    "Random Forest": RandomForestClassifier(),
    "Decision Tree Classifier": DecisionTreeClassifier()
}

for name, clf in classifiers.items():
    print(f"\n============={name}==============")
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(f"\n Accuracy Score: {accuracy_score(y_test, y_pred)}")
    print(f"\n Precision Score: {precision_score(y_test, y_pred)}")
    print(f"\n Recall Score: {recall_score(y_test, y_pred)}")
    print(f"\n F1 Score: {f1_score(y_test, y_pred)}")

# Collect metrics for plotting
smote_metrics = {
    "Model": [],
    "Accuracy": [],
    "Precision": [],
    "Recall": [],
    "F1 Score": []
}

for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    smote_metrics["Model"].append(name)
    smote_metrics["Accuracy"].append(accuracy_score(y_test, y_pred))
    smote_metrics["Precision"].append(precision_score(y_test, y_pred))
    smote_metrics["Recall"].append(recall_score(y_test, y_pred))
    smote_metrics["F1 Score"].append(f1_score(y_test, y_pred))

import numpy as np

# Convert to DataFrame for plotting
undersample_df = pd.DataFrame(undersample_metrics)
smote_df = pd.DataFrame(smote_metrics)

# Plotting the scores comparison
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']
x = np.arange(len(undersample_df["Model"]))  # model positions
width = 0.35  # width of the bars

for metric in metrics:
    plt.figure(figsize=(8, 5))
    plt.bar(x - width/2, undersample_df[metric], width, label='Undersampling', color='skyblue')
    plt.bar(x + width/2, smote_df[metric], width, label='SMOTE Oversampling', color='salmon')
    
    plt.xlabel('Model')
    plt.ylabel(metric)
    plt.title(f'{metric} Comparison: Undersampling vs. SMOTE')
    plt.xticks(ticks=x, labels=undersample_df["Model"], rotation=45)
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.show()


import joblib
from sklearn.ensemble import RandomForestClassifier

# Train model
rfc = RandomForestClassifier()
rfc.fit(X_res, y_res)

# Save model
joblib.dump(rfc, filename=r"C:\Users\HP\OneDrive\Nick final year document\Main Detect\ml-streamlit_app\model\Financial_fraud_model.pkl")

# Load model
model = joblib.load(r"C:\Users\HP\OneDrive\Nick final year document\Main Detect\ml-streamlit_app\model\Financial_fraud_model.pkl")

# Define input (without 'Time', which was dropped during training)
# Also make sure this is passed as a DataFrame with correct column names

# List of columns used in training (X_res)
feature_columns = X_res.columns

# Example input â€” REMOVE 'Time' value (149.62), keep only 29 features
sample_input = [[
    -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443,
    -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507,
    0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348,
    -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478,
    0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705,
    -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731,
    0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215,
    0.0  # 'Amount' column (scaled)
]]

# Convert to DataFrame with same columns
input_df = pd.DataFrame(sample_input, columns=feature_columns)

# Predict
prediction = model.predict(input_df)

# Output result
if prediction[0] == 0:
    print("The transaction is legit")
else:
    print("The transaction is fraud")
